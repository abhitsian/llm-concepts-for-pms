<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Vibe Coding &amp; the Skill Inversion</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  
  <div class="article-card">
    <div class="article-meta">587 words</div><h1>Vibe Coding &amp; the Skill Inversion</h1><div class="article-subtitle">Part 7 of Design Patterns of the AI Era</div><div class="divider">╌╌╌╌</div><hr />
<figure>
<a class="diagram-link" href="https://excalidraw.com/#json=e3SjXOxl6g-Iycj4mLAqo,QLeo2XI3jxo1QgNyv0BDpA">View diagram: Vibe Coding vs Vibe Engineering</a>
<figcaption aria-hidden="true">Vibe Coding vs Vibe Engineering</figcaption>
</figure>
<p>Andrej Karpathy coined “vibe coding” to describe a way of programming where you describe what you want, accept what the AI produces, &amp; move on without really reading the output. Simon Willison drew the line that matters: vibe coding is accepting AI output without understanding it. Vibe engineering is using the same AI tools while maintaining professional judgment about what they produce. The distinction looks subtle. The consequences diverge fast.</p>
<p>The skill inversion happened cuz AI tools made the production of code trivially easy while making the evaluation of code no easier at all. Writing a function went from a 20-minute task to a 30-second prompt. But reviewing whether that function handles edge cases correctly, fits the existing architecture, introduces security vulnerabilities, or creates subtle performance problems — that still requires the same expertise it always did. Possibly more, since AI-generated code tends to be plausible-looking, syntactically clean, &amp; confidently wrong in ways that are harder to spot than typical junior developer mistakes.</p>
<p>The productivity data split along this fault line. Experienced developers who used AI tools as accelerators — generating boilerplate, exploring approaches, handling routine transformations — while continuing to read, evaluate, &amp; revise the output saw genuine 2-3x throughput gains on well-scoped tasks. They knew what correct looked like before the AI produced anything, so they could quickly accept good output &amp; catch bad output.</p>
<p>Developers who stopped reading the code, who treated the AI as an oracle rather than a drafting tool, produced volume without quality. They shipped features faster in the short term &amp; created debugging nightmares in the medium term. The code worked on the happy path cuz the AI is good at happy paths. It failed on edge cases, under load, &amp; in production configurations the AI had never seen.</p>
<h2 id="the-hiring-problem">The Hiring Problem</h2>
<p>This created an uncomfortable hiring &amp; team composition question. The old signal for developer quality — can this person write correct code? — degraded. Almost anyone with AI tools can produce code that compiles &amp; passes basic tests. The new signal is harder to assess: can this person evaluate code they didn’t write, identify subtle problems in plausible-looking implementations, &amp; make sound architectural decisions about AI-generated suggestions?</p>
<p>The ppl who are best at working with AI coding tools are, somewhat paradoxically, the ones who least needed AI coding tools. Senior developers with deep domain knowledge &amp; strong code review instincts became dramatically more productive. Junior developers who hadn’t yet built those instincts became faster at producing code but not better at producing correct code.</p>
<h2 id="what-this-means-for-teams">What This Means for Teams</h2>
<p>The practical response isn’t to ban AI tools or to give everyone unlimited access. It’s to treat AI-augmented development as a skill that requires specific training — not in prompting, but in evaluation. Code review becomes more important, not less. Architectural oversight becomes more important, not less. The investment shifts from “teach ppl to write code” toward “teach people to read code critically &amp; make judgment calls about AI-generated output.”</p>
<p>The vibe coding versus vibe engineering distinction is really about where human judgment sits in the loop. Remove it entirely &amp; you get fast, confident, unreliable output. Keep it in the right places — architecture, edge cases, security, performance — &amp; you get genuine acceleration. The skill that matters most in AI-augmented development is the one AI can’t provide: knowing when the AI is wrong.</p><div class="end-mark">╌╌ end ╌╌</div>
  </div>
  <nav class="article-nav">
  <a href="30-dp-06-the-jevons-paradox-hit-ai.html">&larr; The Jevons Paradox Hit AI</a>
  <a class="nav-index" href="../index.html">Index</a>
  <a href="32-dp-08-task-length-doubled-every-seven-months.html">Task Length Doubled Every 7 Months &rarr;</a>
</nav>
  
</body>
</html>