<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>When Not to Use an LLM</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <div class="bezier-hero"><canvas id="bezier-canvas"></canvas></div>
  <div class="article-card">
    <div class="article-meta">553 words</div><h1>When Not to Use an LLM</h1><div class="article-subtitle">Part 11 of the LLM Concepts for Product Managers series</div><div class="divider">╌╌╌╌</div><hr />
<p>Every problem looks like an LLM problem right now. Text involved? LLM. Any intelligence required? Throw an LLM at it. This is expensive thinking — not just in token costs, but architecturally &amp; organizationally. LLMs are general-purpose, &amp; general-purpose means not optimized for anything specific. For a surprising number of problems teams are solving with LLMs today, specialized solutions exist that are faster, cheaper, &amp; more reliable.</p>
<p>Run through the decision criteria before defaulting to an LLM call. If you need determinism — same output every time for the same input — LLMs are the wrong tool. They’re probabilistic by nature, which is fine for creative tasks but unacceptable for calculations, lookups, or compliance checks. If you’re dealing with structured data in &amp; structured data out — extracting fields from forms, transforming JSON, parsing known formats — regex &amp; parsers handle it faster &amp; cheaper. The LLM functions as an extremely expensive pattern matcher when the patterns aren’t ambiguous. Simple classification tasks — sentiment, spam detection, category assignment — are solved problems in ML. Fine-tuned small models often match or outperform LLMs while costing a hundred times less. Math &amp; formal logic are esp poor fits: LLMs hallucinate calculations &amp; express confident wrongness. Use actual computation — code, calculators, logic engines. High-volume low-value tasks deserve scrutiny too: calling an LLM ten thousand times per user per day for micro-tasks that each deliver marginal value creates terrible aggregate economics.</p>
<h2 id="the-sweet-spot-the-hybrid-architecture">The Sweet Spot &amp; the Hybrid Architecture</h2>
<p>Where LLMs genuinely excel is recognizable territory: tasks that are ambiguous, language-heavy, generative, varied in ways that resist templating, &amp; hard to specify in formal logic. Summarization, open-ended Q&amp;A, complex conversation — this is LLM territory, &amp; the cost is justified cuz no cheaper tool does the job.</p>
<p>The best architectures build hybrid systems. Consider a customer support bot. The naive approach sends everything to an LLM. The smarter approach decomposes: traditional intent classification routes the query, database lookups handle account info, a rule engine covers simple FAQs, &amp; the LLM only handles genuinely complex queries needing reasoning &amp; language generation. The LLM touches maybe 20% of interactions. Everything else uses cheaper, faster, more reliable tools — typically yielding 80% cost reduction with fewer errors on routine cases.</p>
<p>The numbers make it vivid. Sentiment classification via LLM: ~200 tokens per call, $200/day at 100K daily calls. A fine-tuned classifier runs the same volume for ~$1/day. Two orders of magnitude difference, same accuracy on a well-defined task. That flexibility premium is pure waste when the task is stable.</p>
<p>There’s a seductive trap in how easy LLMs are to set up. Write a prompt, get results — no training data, no evaluation pipeline. This front-loads convenience at the cost of ongoing expense. A fine-tuned classifier takes more upfront work, then it’s cheap forever. The correct choice depends on volume &amp; duration, but “the LLM is easier to set up” shouldn’t be where the analysis ends.</p>
<p>The most useful framing is a portfolio view: some features genuinely need LLM reasoning, others use LLMs by default cuz it was easy to prototype that way. Replace the latter with cheaper specialized solutions &amp; redirect the savings into the features where LLM reasoning actually matters.</p><div class="end-mark">╌╌ end ╌╌</div>
  </div>
  <nav class="article-nav">
  <a href="15-09-the-feature-math-changed.html">&larr; The Feature Math Changed</a>
  <a class="nav-index" href="../index.html">Index</a>
  <a href="17-10-build-vs-buy-in-llm-world.html">Build vs. Buy in an LLM World &rarr;</a>
</nav>
  <script src="../js/bezier-core.js"></script>
<script src="../js/diagrams/when-not-to-use.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    var canvas = document.getElementById('bezier-canvas');
    var container = canvas.parentElement;
    WhenNotToUseDiagram(canvas, container);
  });
</script>
</body>
</html>