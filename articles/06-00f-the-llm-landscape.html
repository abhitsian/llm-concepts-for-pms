<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>The LLM Landscape</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>
  <div class="bezier-hero"><canvas id="bezier-canvas"></canvas></div>
  <div class="article-card">
    <div class="article-meta">592 words</div><h1>The LLM Landscape</h1><div class="article-subtitle">Part 0f of LLM Concepts for PMs</div><div class="divider">╌╌╌╌</div><hr />

<p>Not all LLMs come from the same place, &amp; where they come from shapes nearly every product decision you’ll make — cost, privacy, reliability, switching cost. The landscape breaks into two categories that a PM needs to internalize: frontier models &amp; open-weight models.</p>
<p>Frontier models are the best available at any given moment. They’re built by well-funded labs, accessible only through APIs, &amp; you never touch the underlying model. You send data to their servers, they run inference, you pay per token. The three providers PMs encounter most are OpenAI, Anthropic, &amp; Google. OpenAI (GPT-4, o3) is the household name — biggest distribution, strongest brand, the one your CEO has already tried. Anthropic (Claude) has built a reputation for safety, reasoning, &amp; long context handling, &amp; has become esp popular with developer teams. Google (Gemini) is natively multimodal &amp; deeply integrated with Google Cloud, which matters if your company already lives in that ecosystem. Each has slightly different strengths, pricing, &amp; terms of service, but functionally they’re competing on the same frontier — the best general-purpose intelligence money can rent.</p>
<p>Open-weight models are a different animal. Their weights are publicly downloadable, meaning you can run them on your own hardware or through cheaper third-party API providers. The major ones: Meta’s Llama 4 — the largest open model family, backed by Meta’s massive distribution machine. DeepSeek’s R1 — a Chinese lab that matched frontier-level reasoning at roughly 90% less cost &amp; genuinely shook the industry when it dropped. Alibaba’s Qwen 3 — strong multilingual performance, the default choice across Asian markets. Mistral — French, efficient, EU-aligned, favored by companies navigating European data regulation. These aren’t hobbyist experiments. Companies run them in production at serious scale.</p>
<h2 id="what-open-weight-actually-means-for-your-product">What “open-weight” actually means for your product</h2>
<p>When you use an open-weight model, your data never leaves your servers. There are no per-token API fees — you pay for compute hardware instead. But you own the infrastructure burden: hosting, scaling, monitoring, updating. The tradeoff is control &amp; privacy on one side, operational complexity on the other. For products handling sensitive user data — healthcare, finance, enterprise — this tradeoff often tips toward open-weight. For teams that want to ship fast without managing GPUs, frontier APIs are the path of least resistance.</p>
<p>The gap between these two categories is shrinking fast. When GPT-4 launched, nothing open came close. Now open-weight models reach roughly 90% of frontier quality on most tasks, &amp; that gap narrows within months of each new release. This is the single most important dynamic for PMs to understand cuz it means the model layer is commoditizing. The specific model you pick matters less with each passing quarter — what you build around it matters more.</p>
<p>Your choice of model still shapes real product constraints: cost varies by 10x to 100x across providers, data privacy depends on whether user inputs travel to a third party, reliability hinges on API dependency vs self-hosted infrastructure, &amp; switching cost determines how trapped you are if something better comes along. Articles 10 &amp; 15 go deeper on the build-vs-buy &amp; open-model tradeoffs respectively.</p>
<p>The mental model that helps here: think of LLM providers like cloud providers circa 2010. Right now it feels like the choice matters enormously — existentially, even. In five years, it’ll matter about as much as AWS vs GCP — a meaningful but not defining decision. The product you build on top is what defines you. The model underneath is becoming infrastructure.</p><div class="end-mark">╌╌ end ╌╌</div>
  </div>
  <nav class="article-nav">
  <a href="05-00e-three-ways-to-customize-an-llm.html">&larr; Three Ways to Customize an LLM</a>
  <a class="nav-index" href="../index.html">Index</a>
  <a href="07-01-tokens-are-the-new-api-calls.html">Tokens Are the New API Calls &rarr;</a>
</nav>
  <script src="../js/bezier-core.js"></script>
<script src="../js/diagrams/llm-landscape.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    var canvas = document.getElementById('bezier-canvas');
    var container = canvas.parentElement;
    LlmLandscapeDiagram(canvas, container);
  });
</script>
  <script src="../js/nav.js"></script>
</body>
</html>